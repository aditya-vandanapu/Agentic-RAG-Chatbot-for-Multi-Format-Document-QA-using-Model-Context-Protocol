# ğŸ¤– Agentic RAG Chatbot ğŸ“š  
**Multi-Format Document Q&A using Agent-based Retrieval-Augmented Generation and MCP**

![Python](https://img.shields.io/badge/Python-3.9+-blue?logo=python)
![Streamlit](https://img.shields.io/badge/Streamlit-%E2%9D%A4-red?logo=streamlit)
![OpenAI](https://img.shields.io/badge/OpenAI-GPT--3.5--Turbo-green?logo=openai)
![LangChain](https://img.shields.io/badge/LangChain-RAG-yellow)

---

## ğŸ” Overview

A modular AI chatbot to answer questions from uploaded documents using:

- ğŸ§  **GPT-3.5-Turbo via OpenAI**  
- ğŸ” **LangChain + FAISS for Retrieval**  
- ğŸ—‚ï¸ **Multi-format support:** PDF, DOCX, TXT, CSV, PPTX  
- ğŸ§© **Agent-based architecture**:  
  - `IngestionAgent` â†’ Parses & Chunks docs  
  - `RetrievalAgent` â†’ Retrieves context from vector DB  
  - `LLMResponseAgent` â†’ GPT-powered answer generator  
- ğŸ”„ **MCP (Message Carrier Protocol)** â†’ Traceable, explainable message flow  
- ğŸ’» **Streamlit UI**

---

## ğŸ’» How to Run

### ğŸ“¦ 1. Install dependencies

```bash
pip install -r requirements.txt
```
### ğŸ”‘ 2. Setup `.env` file

Create a file named `.env` in the root directory of the project.  
This file will store your environment variables such as API keys.

Add the following line inside `.env` (replace `your_openai_key_here` with your actual OpenAI API key):

```env
OPENAI_API_KEY=your_openai_key_here
```
---

**2. Start Streamlit app**

```markdown
### â–¶ï¸ 3. Start Streamlit App

```bash
streamlit run app.py
```
---

**3. Mermaid Architecture diagram**

```markdown
## ğŸ§  Architecture

```mermaid
flowchart TD
    A[ğŸ“¤ User Uploads Files] --> B[ğŸ§© IngestionAgent<br>â†’ Parse + Chunk]
    B --> C[ğŸ“š RetrievalAgent<br>â†’ Retrieve Relevant Chunks]
    C --> D[ğŸ§  LLMResponseAgent<br>â†’ Answer with GPT-3.5]
    D --> E[âœ… Final Answer + Trace Logs (MCP)]
```
---

**4. Tech Stack list**

```markdown
## âš™ï¸ Tech Stack

- Python  
- Streamlit  
- OpenAI GPT-3.5  
- LangChain  
- FAISS  
- dotenv  
- MCP-style agent communication
```
## ğŸ§© Modular Agents

| Agent            | Role                         |
|------------------|------------------------------|
| IngestionAgent   | Loads + splits docs           |
| RetrievalAgent   | Finds relevant chunks         |
| LLMResponseAgent | Uses GPT to generate answers  |
| utils.mcp.py     | Handles message passing       |

## ğŸ§  Challenges

- Aligning chunk format across formats (CSV, PPTX, PDFs)  
- Handling longer context tokens with OpenAI API  
- Ensuring fast FAISS retrieval  
- Maintaining clean agent boundaries  

## ğŸš€ Future Scope

- Add support for image OCR PDFs  
- Integrate open-source LLMs via Ollama  
- Use async agents for performance  
- Add chat history saving  
## ğŸ“½ï¸ Demo Video

[![Watch Demo](https://img.shields.io/badge/Watch-Demo-blue?logo=video)](https://drive.google.com/file/d/1qXjHp9lNQCcrAF-PuVv3r3uTxwTa-oEE/view?usp=sharing)

## ğŸ‘¨â€ğŸ’» Author

Aditya Vandanapu
